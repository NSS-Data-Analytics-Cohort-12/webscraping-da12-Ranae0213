{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee10fbea-65e7-418f-aa14-1844bdf4e7ea",
   "metadata": {},
   "source": [
    "1. Start by performing a GET request on the url above and convert the response into a BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5010c8bc-716c-4902-ac2f-43b70a3f3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b31e549-b6ae-4a55-a4ed-00b0719c3eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://realpython.github.io/fake-jobs/'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e8e30e-a90a-484b-b497-ccf71d2eab64",
   "metadata": {},
   "source": [
    "a. Use the .find method to find the tag containing the first job title (\"Senior Python Developer\"). Hint: can you find a tag type and/or a class that could be helpful for extracting this information? Extract the text from this title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8eddf3-c3d4-4830-b955-77061c2636df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First job title: Senior Python Developer\n"
     ]
    }
   ],
   "source": [
    "first_job_title = soup.find('h2', class_='title').text.strip()\n",
    "print(f'First job title: {first_job_title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e5bfba-40c1-4210-b230-e1a32c046cdc",
   "metadata": {},
   "source": [
    "b. Now, use what you did for the first title, but extract the job title for all jobs on this page. Store the results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f627c599-f8b3-4dc8-a257-b5724024664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = [job_title.text.strip() for job_title in soup.find_all('h2', class_='title')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95947a90-414a-4ca6-b287-ac02687970ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Senior Python Developer', 'Energy engineer', 'Legal executive', 'Fitness centre manager', 'Product manager', 'Medical technical officer', 'Physiological scientist', 'Textile designer', 'Television floor manager', 'Waste management officer', 'Software Engineer (Python)', 'Interpreter', 'Architect', 'Meteorologist', 'Audiological scientist', 'English as a second language teacher', 'Surgeon', 'Equities trader', 'Newspaper journalist', 'Materials engineer', 'Python Programmer (Entry-Level)', 'Product/process development scientist', 'Scientist, research (maths)', 'Ecologist', 'Materials engineer', 'Historic buildings inspector/conservation officer', 'Data scientist', 'Psychiatrist', 'Structural engineer', 'Immigration officer', 'Python Programmer (Entry-Level)', 'Neurosurgeon', 'Broadcast engineer', 'Make', 'Nurse, adult', 'Air broker', 'Editor, film/video', 'Production assistant, radio', 'Engineer, communications', 'Sales executive', 'Software Developer (Python)', 'Futures trader', 'Tour manager', 'Cytogeneticist', 'Designer, multimedia', 'Trade union research officer', 'Chemist, analytical', 'Programmer, multimedia', 'Engineer, broadcasting (operations)', 'Teacher, primary school', 'Python Developer', 'Manufacturing systems engineer', 'Producer, television/film/video', 'Scientist, forensic', 'Bonds trader', 'Editorial assistant', 'Photographer', 'Retail banker', 'Jewellery designer', 'Ophthalmologist', 'Back-End Web Developer (Python, Django)', 'Licensed conveyancer', 'Futures trader', 'Counselling psychologist', 'Insurance underwriter', 'Engineer, automotive', 'Producer, radio', 'Dispensing optician', 'Designer, fashion/clothing', 'Chartered loss adjuster', 'Back-End Web Developer (Python, Django)', 'Forest/woodland manager', 'Clinical cytogeneticist', 'Print production planner', 'Systems developer', 'Graphic designer', 'Writer', 'Field seismologist', 'Chief Strategy Officer', 'Air cabin crew', 'Python Programmer (Entry-Level)', 'Warden/ranger', 'Sports therapist', 'Arts development officer', 'Printmaker', 'Health and safety adviser', 'Manufacturing systems engineer', 'Programmer, applications', 'Medical physicist', 'Media planner', 'Software Developer (Python)', 'Surveyor, land/geomatics', 'Legal executive', 'Librarian, academic', 'Barrister', 'Museum/gallery exhibitions officer', 'Radiographer, diagnostic', 'Database administrator', 'Furniture designer', 'Ship broker']\n"
     ]
    }
   ],
   "source": [
    "print(job_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2bb085-fceb-498c-9a50-607dbfe7150d",
   "metadata": {},
   "source": [
    "c. Finally, extract the companies, locations, and posting dates for each job. For example, the first job has a company of \"Payne, Roberts and Davis\", a location of \"Stewartbury, AA\", and a posting date of \"2021-04-08\". Ensure that the text that you extract is clean, meaning no extra spaces or other characters at the beginning or end.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d368c6-a91e-4b84-bef1-66561e3e3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = [company.text.strip() for company in soup.find_all('h3', class_='company')]\n",
    "locations = [location.text.strip() for location in soup.find_all('p', class_='location')]\n",
    "dates = [date.text.strip() for date in soup.find_all('time')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7350736e-a579-43f8-8383-4cb3a3e151c8",
   "metadata": {},
   "source": [
    "d. Take the lists that you have created and combine them into a pandas DataFrame. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b11541a-90c8-4b4d-8406-a54d9a7f8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df = pd.DataFrame({\n",
    "    'Job Title': job_titles,\n",
    "    'Company': companies,\n",
    "    'Location': locations,\n",
    "    'Posting Date': dates\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dc367bd-45c4-45c0-9013-102c5f4445ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Job Title                     Company  \\\n",
      "0              Senior Python Developer    Payne, Roberts and Davis   \n",
      "1                      Energy engineer            Vasquez-Davidson   \n",
      "2                      Legal executive  Jackson, Chambers and Levy   \n",
      "3               Fitness centre manager              Savage-Bradley   \n",
      "4                      Product manager                 Ramirez Inc   \n",
      "..                                 ...                         ...   \n",
      "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
      "96            Radiographer, diagnostic                  Holder LLC   \n",
      "97              Database administrator              Yates-Ferguson   \n",
      "98                  Furniture designer             Ortega-Lawrence   \n",
      "99                         Ship broker   Fuentes, Walls and Castro   \n",
      "\n",
      "                Location Posting Date  \n",
      "0        Stewartbury, AA   2021-04-08  \n",
      "1   Christopherville, AA   2021-04-08  \n",
      "2    Port Ericaburgh, AA   2021-04-08  \n",
      "3      East Seanview, AP   2021-04-08  \n",
      "4    North Jamieview, AP   2021-04-08  \n",
      "..                   ...          ...  \n",
      "95      Lake Abigail, AE   2021-04-08  \n",
      "96        Jacobshire, AP   2021-04-08  \n",
      "97        Port Susan, AE   2021-04-08  \n",
      "98     North Tiffany, AA   2021-04-08  \n",
      "99     Michelleville, AP   2021-04-08  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(jobs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a9344d-49b3-4b3a-993c-029a2d464e0a",
   "metadata": {},
   "source": [
    "2a. First, use the BeautifulSoup find_all method to extract the urls.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54144dbd-5f63-4236-96c9-7fb46f12734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_links = [a['href'] for a in soup.find_all('a', class_='card-footer-item') if 'Apply' in a.text]\n",
    "jobs_df['Apply URL (Extracted)'] = apply_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac0aeccc-397e-4ac7-9393-1945383be187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html', 'https://realpython.github.io/fake-jobs/jobs/energy-engineer-1.html', 'https://realpython.github.io/fake-jobs/jobs/legal-executive-2.html', 'https://realpython.github.io/fake-jobs/jobs/fitness-centre-manager-3.html', 'https://realpython.github.io/fake-jobs/jobs/product-manager-4.html', 'https://realpython.github.io/fake-jobs/jobs/medical-technical-officer-5.html', 'https://realpython.github.io/fake-jobs/jobs/physiological-scientist-6.html', 'https://realpython.github.io/fake-jobs/jobs/textile-designer-7.html', 'https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html', 'https://realpython.github.io/fake-jobs/jobs/waste-management-officer-9.html', 'https://realpython.github.io/fake-jobs/jobs/software-engineer-python-10.html', 'https://realpython.github.io/fake-jobs/jobs/interpreter-11.html', 'https://realpython.github.io/fake-jobs/jobs/architect-12.html', 'https://realpython.github.io/fake-jobs/jobs/meteorologist-13.html', 'https://realpython.github.io/fake-jobs/jobs/audiological-scientist-14.html', 'https://realpython.github.io/fake-jobs/jobs/english-as-a-second-language-teacher-15.html', 'https://realpython.github.io/fake-jobs/jobs/surgeon-16.html', 'https://realpython.github.io/fake-jobs/jobs/equities-trader-17.html', 'https://realpython.github.io/fake-jobs/jobs/newspaper-journalist-18.html', 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-19.html', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-20.html', 'https://realpython.github.io/fake-jobs/jobs/product-process-development-scientist-21.html', 'https://realpython.github.io/fake-jobs/jobs/scientist-research-maths-22.html', 'https://realpython.github.io/fake-jobs/jobs/ecologist-23.html', 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-24.html', 'https://realpython.github.io/fake-jobs/jobs/historic-buildings-inspector-conservation-officer-25.html', 'https://realpython.github.io/fake-jobs/jobs/data-scientist-26.html', 'https://realpython.github.io/fake-jobs/jobs/psychiatrist-27.html', 'https://realpython.github.io/fake-jobs/jobs/structural-engineer-28.html', 'https://realpython.github.io/fake-jobs/jobs/immigration-officer-29.html', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-30.html', 'https://realpython.github.io/fake-jobs/jobs/neurosurgeon-31.html', 'https://realpython.github.io/fake-jobs/jobs/broadcast-engineer-32.html', 'https://realpython.github.io/fake-jobs/jobs/make-33.html', 'https://realpython.github.io/fake-jobs/jobs/nurse-adult-34.html', 'https://realpython.github.io/fake-jobs/jobs/air-broker-35.html', 'https://realpython.github.io/fake-jobs/jobs/editor-film-video-36.html', 'https://realpython.github.io/fake-jobs/jobs/production-assistant-radio-37.html', 'https://realpython.github.io/fake-jobs/jobs/engineer-communications-38.html', 'https://realpython.github.io/fake-jobs/jobs/sales-executive-39.html', 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-40.html', 'https://realpython.github.io/fake-jobs/jobs/futures-trader-41.html', 'https://realpython.github.io/fake-jobs/jobs/tour-manager-42.html', 'https://realpython.github.io/fake-jobs/jobs/cytogeneticist-43.html', 'https://realpython.github.io/fake-jobs/jobs/designer-multimedia-44.html', 'https://realpython.github.io/fake-jobs/jobs/trade-union-research-officer-45.html', 'https://realpython.github.io/fake-jobs/jobs/chemist-analytical-46.html', 'https://realpython.github.io/fake-jobs/jobs/programmer-multimedia-47.html', 'https://realpython.github.io/fake-jobs/jobs/engineer-broadcasting-operations-48.html', 'https://realpython.github.io/fake-jobs/jobs/teacher-primary-school-49.html', 'https://realpython.github.io/fake-jobs/jobs/python-developer-50.html', 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-51.html', 'https://realpython.github.io/fake-jobs/jobs/producer-television-film-video-52.html', 'https://realpython.github.io/fake-jobs/jobs/scientist-forensic-53.html', 'https://realpython.github.io/fake-jobs/jobs/bonds-trader-54.html', 'https://realpython.github.io/fake-jobs/jobs/editorial-assistant-55.html', 'https://realpython.github.io/fake-jobs/jobs/photographer-56.html', 'https://realpython.github.io/fake-jobs/jobs/retail-banker-57.html', 'https://realpython.github.io/fake-jobs/jobs/jewellery-designer-58.html', 'https://realpython.github.io/fake-jobs/jobs/ophthalmologist-59.html', 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-60.html', 'https://realpython.github.io/fake-jobs/jobs/licensed-conveyancer-61.html', 'https://realpython.github.io/fake-jobs/jobs/futures-trader-62.html', 'https://realpython.github.io/fake-jobs/jobs/counselling-psychologist-63.html', 'https://realpython.github.io/fake-jobs/jobs/insurance-underwriter-64.html', 'https://realpython.github.io/fake-jobs/jobs/engineer-automotive-65.html', 'https://realpython.github.io/fake-jobs/jobs/producer-radio-66.html', 'https://realpython.github.io/fake-jobs/jobs/dispensing-optician-67.html', 'https://realpython.github.io/fake-jobs/jobs/designer-fashion-clothing-68.html', 'https://realpython.github.io/fake-jobs/jobs/chartered-loss-adjuster-69.html', 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-70.html', 'https://realpython.github.io/fake-jobs/jobs/forest-woodland-manager-71.html', 'https://realpython.github.io/fake-jobs/jobs/clinical-cytogeneticist-72.html', 'https://realpython.github.io/fake-jobs/jobs/print-production-planner-73.html', 'https://realpython.github.io/fake-jobs/jobs/systems-developer-74.html', 'https://realpython.github.io/fake-jobs/jobs/graphic-designer-75.html', 'https://realpython.github.io/fake-jobs/jobs/writer-76.html', 'https://realpython.github.io/fake-jobs/jobs/field-seismologist-77.html', 'https://realpython.github.io/fake-jobs/jobs/chief-strategy-officer-78.html', 'https://realpython.github.io/fake-jobs/jobs/air-cabin-crew-79.html', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-80.html', 'https://realpython.github.io/fake-jobs/jobs/warden-ranger-81.html', 'https://realpython.github.io/fake-jobs/jobs/sports-therapist-82.html', 'https://realpython.github.io/fake-jobs/jobs/arts-development-officer-83.html', 'https://realpython.github.io/fake-jobs/jobs/printmaker-84.html', 'https://realpython.github.io/fake-jobs/jobs/health-and-safety-adviser-85.html', 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-86.html', 'https://realpython.github.io/fake-jobs/jobs/programmer-applications-87.html', 'https://realpython.github.io/fake-jobs/jobs/medical-physicist-88.html', 'https://realpython.github.io/fake-jobs/jobs/media-planner-89.html', 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-90.html', 'https://realpython.github.io/fake-jobs/jobs/surveyor-land-geomatics-91.html', 'https://realpython.github.io/fake-jobs/jobs/legal-executive-92.html', 'https://realpython.github.io/fake-jobs/jobs/librarian-academic-93.html', 'https://realpython.github.io/fake-jobs/jobs/barrister-94.html', 'https://realpython.github.io/fake-jobs/jobs/museum-gallery-exhibitions-officer-95.html', 'https://realpython.github.io/fake-jobs/jobs/radiographer-diagnostic-96.html', 'https://realpython.github.io/fake-jobs/jobs/database-administrator-97.html', 'https://realpython.github.io/fake-jobs/jobs/furniture-designer-98.html', 'https://realpython.github.io/fake-jobs/jobs/ship-broker-99.html']\n"
     ]
    }
   ],
   "source": [
    "print(apply_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014699ae-d159-4782-8739-a82ab426b2db",
   "metadata": {},
   "source": [
    "2 b. Next, get those same urls in a different way. Examine the urls and see if you can spot the pattern of how they are constructed. Then, build the url using the elements you have already extracted. Ensure that the urls that you created match those that you extracted using BeautifulSoup. Warning: You will need to do some string cleaning and prep in constructing the urls this way. For example, look carefully at the urls for the \"Software Engineer (Python)\" job and the \"Scientist, research (maths)\" job.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "500d6107-60ed-49e1-a16b-ecc83c74bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_slug(text):\n",
    "    return text.lower().replace(' ', '-').replace(',', '').replace('(', '').replace(')', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e66cdd63-b1b9-442a-8824-9aced6db7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    " constructed_urls = [\n",
    "    f\"https://realpython.github.io/fake-jobs/{to_slug(title)}-{to_slug(company)}/\"\n",
    "    for title, company in zip(job_titles, companies)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53dafc97-a09c-45f2-a208-eee700414d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df['Apply URL (Constructed)'] = constructed_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7c90005-3241-4415-badd-23c39a9f5707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Job Title                     Company  \\\n",
      "0              Senior Python Developer    Payne, Roberts and Davis   \n",
      "1                      Energy engineer            Vasquez-Davidson   \n",
      "2                      Legal executive  Jackson, Chambers and Levy   \n",
      "3               Fitness centre manager              Savage-Bradley   \n",
      "4                      Product manager                 Ramirez Inc   \n",
      "..                                 ...                         ...   \n",
      "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
      "96            Radiographer, diagnostic                  Holder LLC   \n",
      "97              Database administrator              Yates-Ferguson   \n",
      "98                  Furniture designer             Ortega-Lawrence   \n",
      "99                         Ship broker   Fuentes, Walls and Castro   \n",
      "\n",
      "                Location Posting Date  \\\n",
      "0        Stewartbury, AA   2021-04-08   \n",
      "1   Christopherville, AA   2021-04-08   \n",
      "2    Port Ericaburgh, AA   2021-04-08   \n",
      "3      East Seanview, AP   2021-04-08   \n",
      "4    North Jamieview, AP   2021-04-08   \n",
      "..                   ...          ...   \n",
      "95      Lake Abigail, AE   2021-04-08   \n",
      "96        Jacobshire, AP   2021-04-08   \n",
      "97        Port Susan, AE   2021-04-08   \n",
      "98     North Tiffany, AA   2021-04-08   \n",
      "99     Michelleville, AP   2021-04-08   \n",
      "\n",
      "                                Apply URL (Extracted)  \\\n",
      "0   https://realpython.github.io/fake-jobs/jobs/se...   \n",
      "1   https://realpython.github.io/fake-jobs/jobs/en...   \n",
      "2   https://realpython.github.io/fake-jobs/jobs/le...   \n",
      "3   https://realpython.github.io/fake-jobs/jobs/fi...   \n",
      "4   https://realpython.github.io/fake-jobs/jobs/pr...   \n",
      "..                                                ...   \n",
      "95  https://realpython.github.io/fake-jobs/jobs/mu...   \n",
      "96  https://realpython.github.io/fake-jobs/jobs/ra...   \n",
      "97  https://realpython.github.io/fake-jobs/jobs/da...   \n",
      "98  https://realpython.github.io/fake-jobs/jobs/fu...   \n",
      "99  https://realpython.github.io/fake-jobs/jobs/sh...   \n",
      "\n",
      "                              Apply URL (Constructed)  URLs Match  \n",
      "0   https://realpython.github.io/fake-jobs/senior-...       False  \n",
      "1   https://realpython.github.io/fake-jobs/energy-...       False  \n",
      "2   https://realpython.github.io/fake-jobs/legal-e...       False  \n",
      "3   https://realpython.github.io/fake-jobs/fitness...       False  \n",
      "4   https://realpython.github.io/fake-jobs/product...       False  \n",
      "..                                                ...         ...  \n",
      "95  https://realpython.github.io/fake-jobs/museum/...       False  \n",
      "96  https://realpython.github.io/fake-jobs/radiogr...       False  \n",
      "97  https://realpython.github.io/fake-jobs/databas...       False  \n",
      "98  https://realpython.github.io/fake-jobs/furnitu...       False  \n",
      "99  https://realpython.github.io/fake-jobs/ship-br...       False  \n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "jobs_df['URLs Match'] = jobs_df['Apply URL (Extracted)'] == jobs_df['Apply URL (Constructed)']\n",
    "print(jobs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7965ba-83e3-4ad8-bf48-dc5234ea0b8d",
   "metadata": {},
   "source": [
    " 3a. Start by looking at the page for the first job, https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html. Using BeautifulSoup, extract the job description paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "805117a3-9c45-45b8-8775-fcc1998f9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_job_url = \"https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html\"\n",
    "response_first_job = requests.get(first_job_url)\n",
    "soup_first_job = BeautifulSoup(response_first_job.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea1384c6-ea39-4a76-9a85-0d8adc628d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_job_description = soup_first_job.find('div', class_='description')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11a9d7d2-10c6-4421-8e8c-acaa2e12f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(first_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79192fff-2cfd-419c-b356-cdf411a207b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
